---

title: keras.callbacks

keywords: fastai
sidebar: home_sidebar

summary: "Contains Callbacks that can be used with Tf.keras(TO DO) and Keras."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_keras.callbacks.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CyclicLR" class="doc_header"><code>class</code> <code>CyclicLR</code><a href="https://github.com/gokkulnath/dialga/tree/master/dialga/keras/callbacks.py#L8" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CyclicLR</code>(<strong><code>base_lr</code></strong>=<em><code>0.001</code></em>, <strong><code>max_lr</code></strong>=<em><code>0.006</code></em>, <strong><code>step_size</code></strong>=<em><code>2000.0</code></em>, <strong><code>mode</code></strong>=<em><code>'triangular'</code></em>, <strong><code>gamma</code></strong>=<em><code>1.0</code></em>, <strong><code>scale_fn</code></strong>=<em><code>None</code></em>, <strong><code>scale_mode</code></strong>=<em><code>'cycle'</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>This callback implements a cyclical learning rate policy (CLR).
The method cycles the learning rate between two boundaries with
some constant frequency, as detailed in this paper (<a href="https://arxiv.org/abs/1506.01186">https://arxiv.org/abs/1506.01186</a>).
The amplitude of the cycle can be scaled on a per-iteration or
per-cycle basis.
This class has three built-in policies, as put forth in the paper.
"triangular":
    A basic triangular cycle w/ no amplitude scaling.
"triangular2":
    A basic triangular cycle that scales initial amplitude by half each cycle.
"exp_range":
    A cycle that scales initial amplitude by gamma**(cycle iterations) at each
    cycle iteration.
For more detail, please see paper.</p>
<h1 id="Example">Example<a class="anchor-link" href="#Example">&#182;</a></h1>
<pre><code>```python
    clr = CyclicLR(base_lr=0.001, max_lr=0.006,
                        step_size=2000., mode='triangular')
    model.fit(X_train, Y_train, callbacks=[clr])
```

</code></pre>
<p>Class also supports custom scaling functions:</p>

<pre><code>```python
    clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))
    clr = CyclicLR(base_lr=0.001, max_lr=0.006,
                        step_size=2000., scale_fn=clr_fn,
                        scale_mode='cycle')
    model.fit(X_train, Y_train, callbacks=[clr])
```
</code></pre>
<h1 id="Arguments">Arguments<a class="anchor-link" href="#Arguments">&#182;</a></h1>
<pre><code>base_lr: initial learning rate which is the
    lower boundary in the cycle.
max_lr: upper boundary in the cycle. Functionally,
    it defines the cycle amplitude (max_lr - base_lr).
    The lr at any cycle is the sum of base_lr
    and some scaling of the amplitude; therefore
    max_lr may not actually be reached depending on
    scaling function.
step_size: number of training iterations per
    half cycle. Authors suggest setting step_size
    2-8 x training iterations in epoch.
mode: one of {triangular, triangular2, exp_range}.
    Default 'triangular'.
    Values correspond to policies detailed above.
    If scale_fn is not None, this argument is ignored.
gamma: constant in 'exp_range' scaling function:
    gamma**(cycle iterations)
scale_fn: Custom scaling policy defined by a single
    argument lambda function, where
    0 &lt;= scale_fn(x) &lt;= 1 for all x &gt;= 0.
    mode paramater is ignored
scale_mode: {'cycle', 'iterations'}.
    Defines whether scale_fn is evaluated on
    cycle number or cycle iterations (training
    iterations since start of cycle). Default is 'cycle'.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

