{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasetops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dialga.dataset\n",
    "\n",
    "> Contains commonly used dataset operations which include splitting and creation of validation sets based on various stratergies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from multiprocessing import pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import pandas as pd\n",
    "\n",
    "# path=''.join(sys.argv[1:])\n",
    "\n",
    "# TODO : Need to Write Better Logic for Folder Creation and CLI parsing to pass no of Threads\n",
    "\n",
    "# TODO : Suffix or Prefix Change ?\n",
    "\n",
    "def Resize_Image( filepath ):\n",
    "    im = Image.open( filepath )\n",
    "    im = im.resize((256,256) ,PIL.Image.BILINEAR)\n",
    "    im.save('Resized_'+filepath)\n",
    "               \n",
    "def Resize_Imgs_Directory(path,ext=''):\n",
    "    os.makedirs(\"Resized_\"+path)\n",
    "    files=glob(path+'/*'+ext)\n",
    "    pool = ThreadPool(8)    \n",
    "    pool.map( Resize_Image, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stratified_sample_df(df, col, n_samples,mode='min'):\n",
    "    '''\n",
    "    Add Verbose method to print out log\n",
    "    '''\n",
    "    if mode=='min':\n",
    "        n = min(n_samples, df[col].value_counts().min())\n",
    "        df_ = df.groupby(col).apply(lambda x: x.sample(n))\n",
    "        df_.index = df_.index.droplevel(0)\n",
    "        return df_\n",
    "    elif mode=='max':\n",
    "        max_size = max(n_samples,df[col].value_counts().max())\n",
    "        lst = [df]\n",
    "        for class_index, group in df.groupby(col):\n",
    "            lst.append(group.sample(max_size-len(group), replace=True))\n",
    "        return pd.concat(lst)\n",
    "    else:\n",
    "        max_size = n_samples\n",
    "        lst = [df]\n",
    "        for class_index, group in df.groupby(col):\n",
    "            lst.append(group.sample(max_size-len(group), replace=True))\n",
    "        return pd.concat(lst)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
